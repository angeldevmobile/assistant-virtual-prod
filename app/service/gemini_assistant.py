import google.generativeai as genai
from dotenv import load_dotenv
import os

load_dotenv()
API_KEY = os.getenv("GEMINI_API_KEY")

genai.configure(api_key=API_KEY)

last_question = ""
is_first_question = True


def get_assistant_response(
    question: str, contexto: str = "", more_detail: bool = False
) -> str:
    """
    Asistente conversacional libre. Si se recibe un texto como contexto, responde solo en base a ese documento.
    Si no hay contexto, responde como asistente amable y conversacional.
    """
    global last_question, is_first_question

    if not contexto:
        bienvenida = ""
        if is_first_question:
            bienvenida = "Â¡Hola! ğŸ‘‹ Es un placer ayudarte. ğŸ˜Š\n\n"
            is_first_question = False

        prompt = (
            f"{bienvenida}"
            "Eres un asistente virtual llamado **GurÃº** ğŸ˜Š. SÃ© siempre amable, usa emojis ğŸ‰ğŸ“„âœ… y da respuestas breves, a menos que el usuario pida mÃ¡s detalle.\n\n"
            "INSTRUCCIONES:\n"
            "- Responde a cualquier consulta general de forma amigable y directa.\n"
            "- Si el usuario sube un documento, deberÃ¡s limitarte a responder solo basÃ¡ndote en ese documento.\n\n"
            f"PREGUNTA:\n{question}\n"
        )
    else:
        # SÃ­ hay documento cargado: usar solo ese texto como base
        if not more_detail:
            prompt = f"""
Eres un asistente virtual llamado **GurÃº** ğŸ˜Š. SÃ© siempre amable, usa emojis ğŸ‰ğŸ“„âœ… y da respuestas breves (mÃ¡ximo 3-4 lÃ­neas).

INSTRUCCIONES:
- Responde exclusivamente basÃ¡ndote en el contenido del documento proporcionado.
- Si la respuesta requiere mÃ¡s detalle, invita al usuario a consultarte: "Si deseas, puedo darte mÃ¡s informaciÃ³n. Â¿Quieres que te lo explique con mÃ¡s detalle? ğŸ¤—"
- Si no encuentras la respuesta en el documento, responde: "Lo siento, esa informaciÃ³n no se encuentra en el documento proporcionado. ğŸ™"

DOCUMENTO:
\"\"\"{contexto}\"\"\"

PREGUNTA:
{question}
"""
            last_question = question
        else:
            prompt = f"""
Eres un asistente virtual llamado **GurÃº** ğŸ˜Š. Proporciona ahora una respuesta mÃ¡s detallada y completa, basÃ¡ndote Ãºnicamente en el documento proporcionado ğŸ“„.

DOCUMENTO:
\"\"\"{contexto}\"\"\"

PREGUNTA:
{last_question}

INSTRUCCIONES:
- Ofrece una respuesta mÃ¡s extensa y explicativa.
- Si no encuentras la respuesta en el documento, di: "Lo siento, esa informaciÃ³n no se encuentra en el documento proporcionado. ğŸ™"
"""

    try:
        model = genai.GenerativeModel("gemini-1.5-pro")
        response = model.generate_content(prompt)
        print("Prompt enviado a Gemini:\n", prompt)
        print("Respuesta de Gemini:\n", response.text)
        if response.text.strip().lower() == question.strip().lower():
            return "Â¡Hola! Soy GurÃº ğŸ˜Š. Â¿En quÃ© puedo ayudarte hoy?"
        return response.text
    except Exception as e:
        return f"OcurriÃ³ un error al consultar Gemini: {e}"
